{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T19:47:51.188967Z",
     "iopub.status.busy": "2023-12-03T19:47:51.188410Z",
     "iopub.status.idle": "2023-12-03T19:48:44.650546Z",
     "shell.execute_reply": "2023-12-03T19:48:44.649106Z",
     "shell.execute_reply.started": "2023-12-03T19:47:51.188940Z"
    },
    "id": "ym5EOQPSK8CU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCe71GPiK8CW"
   },
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T19:48:49.790845Z",
     "iopub.status.busy": "2023-12-03T19:48:49.790098Z",
     "iopub.status.idle": "2023-12-03T19:51:00.291573Z",
     "shell.execute_reply": "2023-12-03T19:51:00.290592Z",
     "shell.execute_reply.started": "2023-12-03T19:48:49.790805Z"
    },
    "id": "cdTL03l7K8CX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_path=\"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    device_map = \"auto\",\n",
    "    trust_remote_code = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhIs84NhK8CY"
   },
   "source": [
    "# Creating the Chat Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T19:52:12.735054Z",
     "iopub.status.busy": "2023-12-03T19:52:12.734410Z",
     "iopub.status.idle": "2023-12-03T19:52:12.784855Z",
     "shell.execute_reply": "2023-12-03T19:52:12.783811Z",
     "shell.execute_reply.started": "2023-12-03T19:52:12.735022Z"
    },
    "id": "AlSoz6qwK8CY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\":\"user\",\n",
    "    \"content\": \"Can you tell us 3 cities to visit in Turkey\"\n",
    "}]\n",
    "\n",
    "tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "model_inputs = tokenizer.apply_chat_template(messages, return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T19:52:14.630823Z",
     "iopub.status.busy": "2023-12-03T19:52:14.630262Z",
     "iopub.status.idle": "2023-12-03T19:52:14.641336Z",
     "shell.execute_reply": "2023-12-03T19:52:14.640355Z",
     "shell.execute_reply.started": "2023-12-03T19:52:14.630789Z"
    },
    "id": "jhN7tXNTK8CY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In_JqtNiK8CZ"
   },
   "source": [
    "# Text-Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T19:52:16.491754Z",
     "iopub.status.busy": "2023-12-03T19:52:16.491362Z",
     "iopub.status.idle": "2023-12-03T19:52:34.953469Z",
     "shell.execute_reply": "2023-12-03T19:52:34.952178Z",
     "shell.execute_reply.started": "2023-12-03T19:52:16.491716Z"
    },
    "id": "QCF9m3s4K8CZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generated_ids = model.generate(\n",
    "    model_inputs,\n",
    "    max_new_tokens = 1000,\n",
    "    do_sample = True,\n",
    ")\n",
    "\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T19:52:34.956184Z",
     "iopub.status.busy": "2023-12-03T19:52:34.955491Z",
     "iopub.status.idle": "2023-12-03T19:52:53.726708Z",
     "shell.execute_reply": "2023-12-03T19:52:53.725524Z",
     "shell.execute_reply.started": "2023-12-03T19:52:34.956151Z"
    },
    "id": "MLUyQBEZK8CZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Act as a gourmet chef. I have a friend coming over who is a vegetarian. \\\n",
    "    I want to impress my friend with a special vegetarian dish. \\\n",
    "    What do you recommend? \\\n",
    "    Give me two options, along with the whole recipe for each\"\n",
    "}]\n",
    "\n",
    "model_inputs = tokenizer.apply_chat_template(messages,return_tensors = \"pt\")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs,\n",
    "    max_new_tokens = 1000,\n",
    "    do_sample = True,\n",
    ")\n",
    "\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T19:54:29.298234Z",
     "iopub.status.busy": "2023-12-03T19:54:29.297485Z",
     "iopub.status.idle": "2023-12-03T19:54:31.594255Z",
     "shell.execute_reply": "2023-12-03T19:54:31.593021Z",
     "shell.execute_reply.started": "2023-12-03T19:54:29.298201Z"
    },
    "id": "NRYt59OMK8CZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"\n",
    "}]\n",
    "model_inputs = tokenizer.apply_chat_template(messages,return_tensors = \"pt\")\n",
    "generated_ids = model.generate(\n",
    "    model_inputs,\n",
    "    max_new_tokens = 1000,\n",
    "    do_sample = True,\n",
    ")\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T19:55:17.477792Z",
     "iopub.status.busy": "2023-12-03T19:55:17.477389Z",
     "iopub.status.idle": "2023-12-03T19:55:22.026178Z",
     "shell.execute_reply": "2023-12-03T19:55:22.025194Z",
     "shell.execute_reply.started": "2023-12-03T19:55:17.477762Z"
    },
    "id": "mQWPQByTK8Ca",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What fascinates you about AI?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm fascinated \\\n",
    "    by AI's data analysis and prediction abilities. \\\n",
    "    It has the potential to revolutionize industries and improve problem-solving.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Should people be afraid of AI?\"}\n",
    "]\n",
    "model_inputs = tokenizer.apply_chat_template(messages,return_tensors = \"pt\")\n",
    "generated_ids = model.generate(\n",
    "    model_inputs,\n",
    "    max_new_tokens = 1000,\n",
    "    do_sample = True,\n",
    ")\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T19:55:22.028725Z",
     "iopub.status.busy": "2023-12-03T19:55:22.028310Z",
     "iopub.status.idle": "2023-12-03T19:55:23.271663Z",
     "shell.execute_reply": "2023-12-03T19:55:23.270534Z",
     "shell.execute_reply.started": "2023-12-03T19:55:22.028687Z"
    },
    "id": "5a6-5x13K8Ca",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Türkiye'de en fazla ziyaret edilen 3 şehir hangidir?\"},\n",
    "]\n",
    "model_inputs = tokenizer.apply_chat_template(messages,return_tensors = \"pt\")\n",
    "generated_ids = model.generate(\n",
    "    model_inputs,\n",
    "    max_new_tokens = 1000,\n",
    "    do_sample = True,\n",
    ")\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30580,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
