{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Completions API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Completions API\n",
    "Chat models take a list of messages as input and return a model-generated message as output. Although the chat format is designed to make multi-turn conversations easy, it’s just as useful for single-turn tasks without any conversation.\n",
    "\n",
    "The main input is the messages parameter. Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content. Conversations can be as short as one message or many back and forth turns.\n",
    "\n",
    "Typically, a conversation is formatted with a system message first, followed by alternating user and assistant messages.\n",
    "\n",
    "The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. However note that the system message is optional and the model’s behavior without a system message is likely to be similar to using a generic message such as \"You are a helpful assistant.\"\n",
    "\n",
    "The user messages provide requests or comments for the assistant to respond to. Assistant messages store previous assistant responses, but can also be written by you to give examples of desired behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install openai library\n",
    "# pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "# Carga la clave API desde un archivo JSON\n",
    "with open('keys.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "openai.api_key = config['api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model (LLM) refers to a type of artificial intelligence (AI) model that is capable of generating human-like text by predicting the probability of a given sequence of words. It is trained on massive amounts of data, typically spanning diverse sources like books, articles, websites, and more.\n",
      "\n",
      "LLMs employ deep learning techniques, particularly a neural network architecture called a Transformer, to understand and generate natural language. By learning patterns, context, and relationships from the data they are trained on, these models can generate coherent and contextually accurate text responses.\n",
      "\n",
      "Examples of LLMs include OpenAI's GPT-3 (Generative Pre-trained Transformer 3) and Google's BERT (Bidirectional Encoder Representations from Transformers). These models have demonstrated impressive language understanding and generation capabilities, leading to various applications in chatbots, virtual assistants, content generation, and improved language translation, among others.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "completion = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is a Large Language Model?\"}\n",
    "    \n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can add more prompts and we will get an answer to all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completion = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is a Large Language Model?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain me the architecture behind it\"}\n",
    "    \n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model like OpenAI's GPT-3 is based on a machine learning architecture known as Transformer. The Transformer model was proposed in a paper called \"Attention is All You Need\" by Vaswani et al.\n",
      "\n",
      "At the heart of the Transformer model is the idea of \"attention\", which essentially denotes the model's ability to focus on relevant parts of the input data when generating output data. There are three kinds of attention mechanisms in the Transformer: self-attention, encoder-decoder attention, and masked self-attention.\n",
      "\n",
      "The full Transformer model follows an encoder-decoder structure. The encoder processes the input data (like text in a certain language), and the decoder generates output data (like text in another language). Both the encoder and decoder are composed of multiple layers of Transformer units.\n",
      "\n",
      "However, GPT-3 is based on a modified version of the Transformer model, where only the decoder part is used. This is known as the Transformer Decoder model. The model is \"autoregressive\", meaning it generates outputs one part at a time and uses its past outputs as inputs for producing the next parts.\n",
      "\n",
      "GPT-3 has an impressively large number of parameters - 175 billion! This makes it capable of sophisticated natural language understanding and generation. Each layer of the model captures different kinds of information about the text, allowing the model to generate contextual and coherent responses.\n",
      "\n",
      "The architecture and scale of GPT-3 allow it to perform few-shot learning, where it can understand a new task by seeing a few examples and then generate responses for similar tasks with high accuracy. It can be used for various natural language processing tasks like translation, question-answering, and even generating human-like text.\n",
      "\n",
      "Remember that while GPT-3 is an impressive model, it's only as good as the data it was trained on. It doesn't 'understand' text in the way humans do and its responses are generated based on patterns it has learned from the training data.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Including conversation history is important when user instructions refer to prior messages. Because the models have no memory of past requests, all relevant information must be supplied as part of the conversation history in each request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completion = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Explain me the architecture behind it\"}\n",
    "    \n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like you forgot to mention what \"it\" refers to in your query. The architecture might refer to a building, computer system, software program, or network design, among many other things. Please provide more context so I can give you an accurate answer.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified code to interact as a Chatbot with \"memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta completa de la API: ChatCompletion(id='chatcmpl-8R1uSk9qE1t65oeMYpstCXVpVJiUF', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='¡Hola! Estoy bien, ¿y tú?', role='assistant', function_call=None, tool_calls=None))], created=1701452888, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=12, total_tokens=23))\n",
      "Chatbot: ¡Hola! Estoy bien, ¿y tú?\n",
      "Respuesta completa de la API: ChatCompletion(id='chatcmpl-8R1uaDXTAvPHyXY0LcOQYJ9qXK4kL', choices=[Choice(finish_reason='length', index=0, message=ChatCompletionMessage(content='Claro, LLM es la abreviatura de \"Master of Laws\" o \"Máster en Derecho\" en español. Es un título de posgrado que se otorga a quienes completan un programa específico de estudios en derecho, después de haber obtenido un título de licenciatura en derecho. El programa de LLM se enfoca en áreas específicas del derecho y brinda a los estudiantes la oportunidad de profundizar sus conocimientos y habilidades legales en un campo de su interés.\\n\\nEl programa de LLM generalmente está diseñado para abogados o profesionales que ya tienen experiencia en el campo legal y desean especializarse o adquirir conocimientos más avanz', role='assistant', function_call=None, tool_calls=None))], created=1701452896, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=150, prompt_tokens=40, total_tokens=190))\n",
      "Chatbot: Claro, LLM es la abreviatura de \"Master of Laws\" o \"Máster en Derecho\" en español. Es un título de posgrado que se otorga a quienes completan un programa específico de estudios en derecho, después de haber obtenido un título de licenciatura en derecho. El programa de LLM se enfoca en áreas específicas del derecho y brinda a los estudiantes la oportunidad de profundizar sus conocimientos y habilidades legales en un campo de su interés.\n",
      "\n",
      "El programa de LLM generalmente está diseñado para abogados o profesionales que ya tienen experiencia en el campo legal y desean especializarse o adquirir conocimientos más avanz\n"
     ]
    }
   ],
   "source": [
    "# Historial de mensajes (inicialmente vacío)\n",
    "chat_history = []\n",
    "# ...\n",
    "\n",
    "# Función para obtener la respuesta del chatbot\n",
    "def get_chatbot_response(user_input, chat_history):\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=chat_history,\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    # Imprime la respuesta completa para depuración\n",
    "    print(\"Respuesta completa de la API:\", response)\n",
    "\n",
    "    # Asumiendo que la respuesta es un objeto y accediendo a sus atributos\n",
    "    chatbot_message = response.choices[0].message.content\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": chatbot_message})\n",
    "    return chatbot_message\n",
    "\n",
    "# Historial de mensajes inicial\n",
    "chat_history = []\n",
    "\n",
    "# Ejemplo de uso\n",
    "while True:\n",
    "    user_input = input(\"Tú: \")\n",
    "    if user_input.lower() == 'salir':\n",
    "        break\n",
    "    print(\"Chatbot:\", get_chatbot_response(user_input, chat_history))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
