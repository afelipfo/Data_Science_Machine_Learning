{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de sentimientos: Enfoque de Aprendizaje de Máquina\n",
    "\n",
    "En este notebook, vas a usar [scikit-learn](https://scikit-learn.org/), una de las librerías mas importantes para construcción de modelos de aprendizaje de máquina, para la construcción de un clasificador de sentimientos. El objetivo es identificar si una crítica de una película es positiva o negativa.  Este notebook esta dividido en tres secciones que representan las etapas típicas en la construcción de soluciones de procesamiento de lenguaje natural.\n",
    "\n",
    "- *Procesamiento del texto*: Vamos a entender el dataset y procesar el texto.\n",
    "- *Estrategia de representación*: Construiremos una representación básica de bolsa de palabras utilizando la funcionalidad CountVectorizer de sklearn.\n",
    "- *Modelamiento y evaluación*: Entrenaremos un clasificador Naive Bayes y evaluaremos su desempeño. También utilizaremos el modelo construido para predecir la polaridad en texto construido por nosotros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Lo primero que vamos a realizar es la importación de las librerías necesarias para la construcción de nuestro clasificador\n",
    "\n",
    "## Scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "## Librerias para graficación \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLTK es una librería particular para PLN. Tiene muchas funcionalidades entre ellas stemming y lista de palabras de parada.\n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "stemmer = nltk.stem.SnowballStemmer('spanish') # Vamos a utlizar el Snowball Stemmer para realizar stemming (nos permite llevar las palabras a una forma estandar). \n",
    "nltk.download('stopwords') # Lista de palabras de parada en español."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Procesamiento del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Dataset\n",
    "\n",
    "Vamos a utlizar una versión modificada del dataset abierto de criticas de películas Españolas de Kaggle: [Críticas películas filmaffinity en Español](https://www.kaggle.com/datasets/ricardomoya/criticas-peliculas-filmaffinity-en-espaniol). El dataset se encuentra en archivo csv \"Tutorial-NLP_Analisis_de_Sentimientos.csv\".\n",
    "\n",
    "Para leer este archivo y operarlo vamos a hacer uso de la librería de python [Pandas](https://pandas.pydata.org/) y su método de lectura [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>polaridad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>Campeones</td>\n",
       "      <td>Comedia</td>\n",
       "      <td>Quién es normal?</td>\n",
       "      <td>Me parece una película muy divertida, emotiva ...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>Villaviciosa de al lado</td>\n",
       "      <td>Comedia</td>\n",
       "      <td>Resurrección de la caspa</td>\n",
       "      <td>Un reparto imposible, un argumento que puede r...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>Perfectos desconocidos</td>\n",
       "      <td>Comedia</td>\n",
       "      <td>La vida misma</td>\n",
       "      <td>¿ Que es lo que nos hace mejores o peores pers...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>Tres metros sobre el cielo</td>\n",
       "      <td>Romance</td>\n",
       "      <td>¡VOCALIZA UN POCO MEJOR QUE NO SE TE ENTIENDE....</td>\n",
       "      <td>Cuando uno ve el éxito que ha tenido esta pelí...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Alatriste</td>\n",
       "      <td>Aventuras</td>\n",
       "      <td>niños jugando a ser mayores</td>\n",
       "      <td>Siento erigirme en portador de malas nuevas, m...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       film_name     gender  \\\n",
       "2462                   Campeones    Comedia   \n",
       "2046     Villaviciosa de al lado    Comedia   \n",
       "2415      Perfectos desconocidos    Comedia   \n",
       "1881  Tres metros sobre el cielo    Romance   \n",
       "24                     Alatriste  Aventuras   \n",
       "\n",
       "                                           review_title  \\\n",
       "2462                                   Quién es normal?   \n",
       "2046                           Resurrección de la caspa   \n",
       "2415                                      La vida misma   \n",
       "1881  ¡VOCALIZA UN POCO MEJOR QUE NO SE TE ENTIENDE....   \n",
       "24                          niños jugando a ser mayores   \n",
       "\n",
       "                                            review_text polaridad  \n",
       "2462  Me parece una película muy divertida, emotiva ...  positivo  \n",
       "2046  Un reparto imposible, un argumento que puede r...  negativo  \n",
       "2415  ¿ Que es lo que nos hace mejores o peores pers...  positivo  \n",
       "1881  Cuando uno ve el éxito que ha tenido esta pelí...  negativo  \n",
       "24    Siento erigirme en portador de malas nuevas, m...  negativo  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Tutorial-NLP_Analisis_de_Sentimientos.csv', sep=',', header=0, index_col= None, engine='python', \n",
    "                 usecols=['film_name','gender','review_title','review_text','polaridad'])\n",
    "\n",
    "## Una vez realizado el cargue del dataset en un dataframe de pandas podemos explorarlo!\n",
    "## Revisemos 5 ejemplos del dataset.\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada ejemplo del dataset (fila) representa una crítica realizada por un usuario a una película. \n",
    "\n",
    "- La columna '*film_name*' indica el nombre de la película objeto de la crítica. \n",
    "- La columna '*gender*' indica el género de la película.\n",
    "- La columna '*review title*' es el título de la crítica.\n",
    "- La columna '*polaridad*' es la categoría/label asignado a la crítica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos la critica en la fila número 2895 en nuestro dataset. Para acceder vamos a utilizar [iloc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html) que nos permite seleccionar por indice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Me aburrí.  No le vi la gracia a Ocho Apellidos Vascos, mucho menos se la voy a ver a este desgraciado efecto secundario.  El caso es que empecé a verla con ganas, a ver si por lo menos me reía de algún chiste, pero, o no los distinguí, o no existen en el texto o ando espesito yo.  El guión es un absurdo sin gracia, porque hay absurdos graciosos, pero no este, y si no hay guión no hay peli por mucho que tengamos a Karra y a la Sardá.  Me los imagino a los dos compartiendo unas kokotxas con xamfaina y haciéndose confidencias acerca de lo que tiene que hacer uno para que le quede una pensión decente.En realidad esta es la crítica de las tres cuartas partes de la película, el final me cogió haciéndome el colacao para irme a la cama.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2895].review_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente la crítica es negativa, pero revisemos su categoría/label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negativo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2895].polaridad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos ahora cuantos ejemplos de críticas negativas y positivas tenemos en nuestro dataset. Esta información es relevante para:\n",
    "- Seleccionar la relación entre particiones de entrenamiento y testing de nuestro dataset.\n",
    "- Conocer si las clases estas balanceadas (cada clase tiene el mismo número de ejemplos).\n",
    "- Seleccionar le modelo de aprendizaje de máquina mas apropiado.\n",
    "\n",
    "Vamos a utilizar la función [catplot](https://seaborn.pydata.org/generated/seaborn.catplot.html) de la librería seaborn para la elaboración de un histograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(-2.700000000000003, 0.5, 'Conteo')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x='polaridad', kind='count', color='r', data=df)\n",
    "plt.title('Distribución de Ejemplos')\n",
    "plt.xlabel('Polaridad')\n",
    "plt.ylabel('Conteo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del histograma se puede evidenciar:\n",
    "- Tenemos 1857 ejemplos de cada clase (positivo, negativo). Las clases están perfectamente balanceadas.\n",
    "- En total tenemos 3714 ejemplos en el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Unificación de texto\n",
    "\n",
    "En nuestro dataset tenemos dos fuentes de información textual de la crítica la columna review_text y la columna review_title. Vamos a concatenar ambos textos en una sola nueva columna que denominaremos \"*texto*\". Usaremos su contenido para construir una representación de bolsa de palabras y posteriormente un modelo de Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>polaridad</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Volver</td>\n",
       "      <td>Drama</td>\n",
       "      <td>VOLVER AL PASADO, LA ETERNA RECURRENCIA</td>\n",
       "      <td>La última película de Almodóvar vuelve a ser u...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>VOLVER AL PASADO, LA ETERNA RECURRENCIA La últ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mar adentro</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Genialmente Horrible</td>\n",
       "      <td>Sinceramente, pienso que el fondo de la crític...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>Genialmente Horrible Sinceramente, pienso que ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Celda 211</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>sobrevaloradísima</td>\n",
       "      <td>Lo siento, pero fui a verla con muchas expecta...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>sobrevaloradísima Lo siento, pero fui a verla ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Las aventuras de Tadeo Jones</td>\n",
       "      <td>Animación</td>\n",
       "      <td>Insultante.</td>\n",
       "      <td>La pelicula es muy mala. Incluso más que mala,...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>Insultante. La pelicula es muy mala. Incluso m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mientras dure la guerra</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Valiente Unamuno, o justicia para Unamuno, o r...</td>\n",
       "      <td>Una buena película, quizá gran película y muy ...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>Valiente Unamuno, o justicia para Unamuno, o r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      film_name     gender  \\\n",
       "0                        Volver      Drama   \n",
       "1                   Mar adentro      Drama   \n",
       "2                     Celda 211   Thriller   \n",
       "3  Las aventuras de Tadeo Jones  Animación   \n",
       "4       Mientras dure la guerra      Drama   \n",
       "\n",
       "                                        review_title  \\\n",
       "0            VOLVER AL PASADO, LA ETERNA RECURRENCIA   \n",
       "1                               Genialmente Horrible   \n",
       "2                                  sobrevaloradísima   \n",
       "3                                        Insultante.   \n",
       "4  Valiente Unamuno, o justicia para Unamuno, o r...   \n",
       "\n",
       "                                         review_text polaridad  \\\n",
       "0  La última película de Almodóvar vuelve a ser u...  positivo   \n",
       "1  Sinceramente, pienso que el fondo de la crític...  negativo   \n",
       "2  Lo siento, pero fui a verla con muchas expecta...  negativo   \n",
       "3  La pelicula es muy mala. Incluso más que mala,...  negativo   \n",
       "4  Una buena película, quizá gran película y muy ...  positivo   \n",
       "\n",
       "                                               texto  \n",
       "0  VOLVER AL PASADO, LA ETERNA RECURRENCIA La últ...  \n",
       "1  Genialmente Horrible Sinceramente, pienso que ...  \n",
       "2  sobrevaloradísima Lo siento, pero fui a verla ...  \n",
       "3  Insultante. La pelicula es muy mala. Incluso m...  \n",
       "4  Valiente Unamuno, o justicia para Unamuno, o r...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['texto'] = df['review_title'] + ' ' + df['review_text']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Función de procesamiento\n",
    "\n",
    "Vamos a definir ahora una función \"*processing_text*\" encargada de modificar el texto de forma apropiada para ser usado en la representación. Es importante aclarar que el procesamiento cambia de acuerdo al dataset y el problema que se esta resolviendo, no existe una única fórmula mágica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* processing_text\n",
    "* @param texto str\n",
    "* @return processed_feature str\n",
    "'''\n",
    "def processing_text(texto):\n",
    "    # Paso 1: Remover con un expresión regular carateres especiales (no palabras).\n",
    "    processed_feature = re.sub(r'\\W', ' ', str(texto))\n",
    "    # Paso 2: Remover ocurrencias de caracteres individuales\n",
    "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "    # Paso 3: Remover números (Ocurrencias muy esporádicas en nuestro dataset)\n",
    "    processed_feature = re.sub(r'[0-9]+', ' ', processed_feature)\n",
    "    # Paso 4: Simplificar espacios concecutivos a un único espacio entre palabras\n",
    "    processed_feature = re.sub(' +', ' ', processed_feature)\n",
    "    # Paso 5: Pasar todo el texto a minúsculas    \n",
    "    processed_feature = processed_feature.lower()\n",
    "    # Paso 6: Aplicar stemming. Es una forma de enviar las palabras a una raiz común simplificando de esta manera el vocabulario. \n",
    "    #         por ejemplo las palabras (absurdo, absurdos) que estan en el review 2895 seran llevados a la raiz común \"absurd\"\n",
    "    #         y de esta forma se evita tener dos palabras diferentes con el mismo significado en nuestro vocabulario.\n",
    "    processed_feature = \" \".join([stemmer.stem(i) for i in processed_feature.split()])\n",
    "    \n",
    "\n",
    "    return processed_feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya tenemos nuestra función de procesamiento la vamos a aplicar a nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero vamos extraer del dataframe la columna texto y la polaridad y las almacenaremos en las variables\n",
    "# texto_para_procesar y labels respectivamente\n",
    "texto_para_procesar = df['texto'].values\n",
    "labels = df['polaridad'].values\n",
    "\n",
    "# El texto ya procesado de cada ejemplo en nuestro dataset lo almacenaremos en la variable \"texto_procesado\"\n",
    "texto_procesado = []\n",
    "for sentence in range(0, len(texto_para_procesar)):\n",
    "    procesado = processing_text(texto_para_procesar[sentence])\n",
    "    texto_procesado.append(procesado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin procesar:\n",
      "No pude acabar de verla Me aburrí.  No le vi la gracia a Ocho Apellidos Vascos, mucho menos se la voy a ver a este desgraciado efecto secundario.  El caso es que empecé a verla con ganas, a ver si por lo menos me reía de algún chiste, pero, o no los distinguí, o no existen en el texto o ando espesito yo.  El guión es un absurdo sin gracia, porque hay absurdos graciosos, pero no este, y si no hay guión no hay peli por mucho que tengamos a Karra y a la Sardá.  Me los imagino a los dos compartiendo unas kokotxas con xamfaina y haciéndose confidencias acerca de lo que tiene que hacer uno para que le quede una pensión decente.En realidad esta es la crítica de las tres cuartas partes de la película, el final me cogió haciéndome el colacao para irme a la cama.\n",
      "---------------------------------\n",
      "Procesado:\n",
      "no pud acab de verl me aburr no le vi la graci ocho apell vasc much men se la voy ver este desgraci efect secundari el cas es que empec verl con gan ver si por lo men me rei de algun chist per no los distingu no exist en el text ando espesit yo el guion es un absurd sin graci porqu hay absurd gracios per no este si no hay guion no hay peli por much que teng karr a la sard me los imagin los dos compart unas kokotx con xamfain hac confident acerc de lo que tien que hac uno par que le qued una pension decent en realid esta es la critic de las tres cuart part de la pelicul el final me cog hac el colaca par irme la cam\n"
     ]
    }
   ],
   "source": [
    "# Comparemos ahora la crítica 2895 procesada vs no procesada.\n",
    "print(\"Sin procesar:\")\n",
    "print(texto_para_procesar[2895])\n",
    "print(\"---------------------------------\")\n",
    "print(\"Procesado:\")\n",
    "print(texto_procesado[2895])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "\n",
    "Debido al proceso de stemming ahora el texto es mucho más difícil de leer, sin embargo, el stemming nos permitirá tener un vocabulario reducido.\n",
    "Ahora solo nos hace falta una etapa del procesamiento que es la eliminación de *palabras de parada*. Las palabras de parada son las palabras más comunes en cualquier idioma:  artículos, preposiciones, pronombres, conjunciones, etc. y no agregan mucha información sobre la semántica del texto. Veamos una lista de estas palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La eliminación de palabras de parada no es apropiada para todas las tareas de procesamiento de lenguaje natural. Por ejemplo, si queremos construir un modelo que genere texto coherente es necesario preservar la estructura sintáctica del lenguaje y esto incluye por supuesto las palabras de parada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Representación del texto\n",
    "\n",
    "En esta etapa debemos tomar el texto procesado y representarlo de alguna forma que nos permita operarlo apropiadamente. Vamos a usar la representación más básica que es la *bolsa de palabras*.  Una bolsa de palabras es una representación de texto que describe la ocurrencia de palabras dentro de un documento e implica:\n",
    "\n",
    "- Un vocabulario de palabras.\n",
    "- Una ponderación de la presencia de palabras del vocabulario. La forma mas simple es realizar el conteo de las ocurrecias de las palabras del vocabulario en el texto.\n",
    "\n",
    "Se llama *bolsa de palabras*, porque se descarta cualquier información sobre el orden o la estructura de las palabras en el documento. El modelo solo se preocupa por si las palabras conocidas ocurren en el documento o no. Para construir una bolsa de palabras en sklearn podemos hacer uso de [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) que construye el vocabulario de palabras de nuestro conjunto de datos y transforma el texto en un vector de conteo de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de palabras\n",
    "vectorizer = CountVectorizer(max_features=2500, stop_words=stopwords.words('spanish'))\n",
    "# max_features representa el tamaño del vocabulario. Vamos a permitir 2500 palabras/términos.\n",
    "# stop_words le indicamos las palabras de parada para que las ignore en el vocabulario. \n",
    "\n",
    "# Ahora le solicitamos utilizando nuestro conjunto de datos que construya el vocabulario y tambien transforme nuestro texto\n",
    "texto_features = vectorizer.fit_transform(texto_procesado).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Vocabulario\n",
    "\n",
    "Revisemos el vocabulario. *CountVectorizer* tomo todas las críticas del dataset, extrajo todas las palabras diferentes y calculo el número de apariciones. De todas las palabras mantuvo las 2500 más frecuentes sin tener en cuenta la lista de palabras de parada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abaj',\n",
       " 'abandon',\n",
       " 'abarc',\n",
       " 'aberr',\n",
       " 'abiert',\n",
       " 'abord',\n",
       " 'abre',\n",
       " 'absolut',\n",
       " 'absurd',\n",
       " 'abuel']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para ver las primeras 10 palabras del vocabulario podemos hacer uso del método get_feature_names\n",
    "vectorizer.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Representación vectorial del texto\n",
    "\n",
    "Una vez construido el vocabulario, *CountVectorizer* construye una representación vectorial de cada crítica. El valor de cada dimensión de dicho vector corresponde al número  de ocurrencias de una palabra del vocabulario. Este vector tendrá por lo tanto tantas dimensiones como palabras en el vocabulario, en nuestro caso 2500. \n",
    "\n",
    "Volvamos al texto procesado de la crítica 2895:\n",
    "\n",
    "*\"no pud acab de verl me aburr no le vi la graci ocho apell vasc much men se la voy ver este desgraci efect secundari el cas es que empec verl con gan ver si por lo men me rei de algun chist per no los distingu no exist en el text ando espesit yo el guion es un absurd sin graci porqu hay absurd gracios per no este si no hay guion no hay peli por much que teng karr a la sard me los imagin los dos compart unas kokotx con xamfain hac confident acerc de lo que tien que hac uno par que le qued una pension decent en realid esta es la critic de las tres cuart part de la pelicul el final me cog hac el colaca par irme la cam\n",
    "\"*\n",
    "\n",
    "Como se pueden dar cuenta la palabra *absurd* aparece dos veces en el texto. Esta palabra es la número 9 en nuestro vocabulario, por lo tanto la representación vectorial de la crítica 2895 deberá contener un 2 (frecuencia) en la dimensión 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "[0 0 0 0 0 0 0 2 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(texto_features[2895])) # Longitud del vector que representa a la crítica 2895. \n",
    "print(texto_features[2895][1:100]) # 100 primeras posiciones del vector de la crítica. Puede ubicar la dimensión correspondiente a la palabra \"absurb\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelamiento y evaluación\n",
    "\n",
    "Ahora que tenemos nuestra representación, es necesario construir y evaluar nuestro modelo de Naive Bayes. Necesitamos un subconjunto de los datos para construir nuestro modelo probabilístico (train) y otro subconjunto para evaluarlo (test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca dividimos nuestro dataset en entrenamiento y texto. 20% para evaluar (test) y 80% para entrenamiento (train). \n",
    "# En las variables X_ quedaran almacenados las presentaciones vectoriales de las críticas.\n",
    "# En las variables y_ las etiquetas o categorias (polaridad de la crítica).\n",
    "X_train, X_test, y_train, y_test = train_test_split(texto_features, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a entrenar el modelo. En sklearn [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomialnb#sklearn.naive_bayes.MultinomialNB) nos permite entrenar un modelo de Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora entrenemos un modelo simple. Ya conocenos Naive Bayes!!\n",
    "nb = MultinomialNB()\n",
    "# El método fit en sklearn permite ejecutar el proceso de entrenamiento.\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Evaluación\n",
    "\n",
    "Listo, ya tenemos nuesto modelo de Naive Bayes entrenado, es necesario evaluarlo con el cunjunto de test. Vamos a utilizar una metrica conocida como accuracy que representa la relación de críticas para las cuales el modelo predijo correctamente la crítica. Un valor de 1 en el accuracy indica que a todas las criticas se les predijo correctamente la polaridad, mientras que un accuracy de 0 indica que el modelo fallo todas sus predicciones. Existen otras métricas de evaluación pero por ahora lo vamos a mantener simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8586810228802153\n"
     ]
    }
   ],
   "source": [
    "# Ahora vamos a evaluar que tan bueno es nuestro modelo NB, utlilizando el conjunto de datos de test.\n",
    "# Para predecir utlizamos el método predict.\n",
    "\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "# Ahora calculamos el score de accuracy enviando las predicciónes y los valores reales de polaridad.\n",
    "print(accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un accuracy mayor al 80% no esta nada mal para un modelo simple como Naive Bayes. Vamos ahora a jugar un poco con el modelo y enviarle texto que nosotros construyamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASO 1 procesamiento: fue la mejor pelicul que he vist en mi vid\n",
      "PASO 2 representación:   (0, 1484)\t1\n",
      "  (0, 1733)\t1\n",
      "  (0, 2450)\t1\n",
      "  (0, 2469)\t1\n",
      "PASO 3 predecir con el modelo: ['positivo']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Utilizemos la siguiente frase de test (sientanse en la libertad de cambiarla).\n",
    "test = \"Fue la mejor pelicula que he visto en mi vida\"\n",
    "\n",
    "# Recuerden el modelo recibe la representación vectorial del texto, no el texto en bruto. Debemos procesar y representar el texto.\n",
    "\n",
    "test_procesado = processing_text(test) # Aplicamos nuestra función de procesamiento\n",
    "print(\"PASO 1 procesamiento:\" ,test_procesado) \n",
    "\n",
    "test_bow =vectorizer.transform([test_procesado]) # Ahora lo representamos como una bolsa de palabras. El vector resultante tiene 2500 posiciones.\n",
    "print(\"PASO 2 representación:\" ,test_bow) # En esa impresion no aparecen las 2500 posiciones del vector, solo la lista de posiciones que son diferentes de cero.\n",
    "\n",
    "# Ahora que ya lo tenemos en la representación adecuada lo podemos enviar al modelo para que este prediga su polaridad.\n",
    "clase_test = nb.predict(test_bow)\n",
    "print(\"PASO 3 predecir con el modelo:\" ,clase_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifique el texto en la variable test para que el modelo ahora prediga una polaridad negativa. ¿Se le ocurre alguna forma de confundir al modelo para que la predicción sea incorrecta?, pruebe por ejemplo doble negaciones en el texto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
